{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "base_url = 'http://karten.guedels.ch/'\n",
    "img_dir = 'map_images/'\n",
    "all_maps_query = 'users.php?lastMaps=all'\n",
    "\n",
    "r = requests.get(base_url)\n",
    "\n",
    "with open('tmp.html', 'w', encoding='utf-8') as test_file:\n",
    "    test_file.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='scrape_maps.log', encoding='utf-8', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "find_digits = re.compile('\\d+')\n",
    "\n",
    "img_numbers = [re.findall(find_digits, match)[0] for match in re.findall('map=\\d+', html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = 'maps'\n",
    "if not os.path.exists('maps'):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(img_url, filename):\n",
    "    return urllib.request.urlretrieve(img_url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_download_image(base_url, img_dir, save_dir, img, exts):\n",
    "    for i, ext in enumerate(exts):\n",
    "        img_url = f'{base_url}{img_dir}{img}{ext}'\n",
    "        filename = f'{save_dir}/{img}{ext}'\n",
    "        try:\n",
    "            if i > 0:\n",
    "                logging.debug(f'\\tRetrying with {ext}... ')\n",
    "            download_image(img_url, filename)\n",
    "            return True\n",
    "        except HTTPError as e:\n",
    "            logging.debug(f'\\t{str(e)}: {filename}')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_imgs_to_downloads(save_dir, imgs, exts):\n",
    "    imgs_to_exclude = []\n",
    "    imgs_to_download = []\n",
    "    for img in imgs:\n",
    "        file_exists = False\n",
    "        for ext in exts:\n",
    "            filename = f'{save_dir}/{img}{ext}'\n",
    "            file_exists = file_exists or os.path.exists(filename)\n",
    "        if file_exists:\n",
    "            imgs_to_exclude.append(img)\n",
    "        else:\n",
    "            imgs_to_download.append(img)\n",
    "    return imgs_to_download, imgs_to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "import itertools\n",
    "\n",
    "def download_images(base_url, img_dir, save_dir, imgs):\n",
    "    exts = ['.jpg', '.png', '.JPG', '.PNG']\n",
    "\n",
    "    imgs_to_download, imgs_to_exclude  = find_imgs_to_downloads(save_dir, imgs, exts)\n",
    "\n",
    "    if imgs_to_exclude:\n",
    "        print(f'Ignoring images: {\",\".join(imgs_to_exclude)}')\n",
    "\n",
    "    if imgs_to_download:\n",
    "        print(f'Downloading images: {\",\".join(imgs_to_download)}')\n",
    "\n",
    "    failed_imgs = []\n",
    "    for img in imgs_to_download:\n",
    "        success = try_download_image(base_url, img_dir, save_dir, img, exts)\n",
    "        if not success:\n",
    "            failed_imgs.append(img)\n",
    "    if failed_imgs:\n",
    "        print(f'Failed to download: {\",\".join(failed_imgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ignoring images: 2814,2780,564,2561,2386,2822,285,246,447,2722,251,1057,1935,2713,2818,2816,2711,2814,2822,2821,2820,2819,2818,2817,2816,2815,2814,2813,1304,2324,2328,2325,2266,2165,2087,375,2004,1912\nTook 0.0051 seconds to download.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "time_start = time()\n",
    "download_images(base_url, img_dir, save_dir, img_numbers)\n",
    "time_end = time()\n",
    "print(f'Took {time_end - time_start:2.4f} seconds to download.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}